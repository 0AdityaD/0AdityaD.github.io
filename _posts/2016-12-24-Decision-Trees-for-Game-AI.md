---
layout: post
title: Decision Tree Search for Game AI
---

Trees in computer science can be used to represent and organize a variety of data. For example, binary search trees can be used to order data according to a defined ordering property. m-ary decision trees can be used to model cascading effects of decisions to manipulate and change an initial state. A good way to imagine this would be to think of a simple coin flipping game where a player tries to guess the correct outcome of a coin flip. After n turns in the game, the set of possible coin histories has a cardinality of 2^N because there are 2 choices for each of the n coins. These 2^N coin spaces can be thought of as 2^N paths from the root of a tree to its leaves. An example is shown below.

![Coin Flip Decision Tree]({{ site.baseurl }}/images/dtht.gif "Coin Flip Decision Tree")

These trees can also be used to model more complex sets of states and actions such as a game of chess or a game of tetris. The nth level in a tree represents the possible game states n moves after the initial state. Each node in the tree has a variable number of children depending on the number of possible actions or moves possible from the current game state. This tree is known as a decision tree, and it can be used to "lookahead" in games as a form of artificial intelligence or even in knapsacking. As is obvious from the game chess, these trees can get extremely large very quickly. In fact the rate of growth of these trees is O(m^n) where m is the max number of children of a node in the tree and n is its height.

The state of the game at each node can be evaluated using a game scoring function. In order to determine the best sequence of moves from a certain game state max game state path can be recursively calculated by performing a depth first search on the nodes of the tree. I implemented a very simple version of this DFS to implement a Tetris AI that placed 15000 pieces on a tetris board before running out of space on the board. Two of the most common strategies for calculating the best possible moves are maximin and minimax. Maximin picks the moves that maximize the increase in game score, and minimax picks the moves that minimize the loss in game score. However, the exponential growth of game states presents a scalability issue that limits our ability to use brute force depth first search to select best possible moves when playing a game. One naive solution to this issue would be to prune dead end paths that lead to very low scoring states before reaching a leaf. However, in practice this method does not help solve the scalibility issue. This is the case especially in games that require significant "look ahead" to observe differences in game state scores such as chess. Hence, computer scientists have come up with some randomized approximation algorithms to estimate the best possible sequence of moves.

Monte Carlo Tree Search is a randomized approximation algorithm to guess the best combination of moves. MCTS selects a random combination of moves and keeps expanding until either a win or loss in the game is achieved. The result of these random moves is backpropagated up the tree to reset probabilities of success. The idea is that this algorithm can keep running until the allotted time for a move is elapsed. Then the computer simply chooses the set of moves with the best probability and plays the move. 

One of the most innovative uses of MCTS with decision trees is in the AlphaGo program devloped by Google DeepMind that beat the world Go champion. They used neural networks to make MCTS more efficient. This worked by keeping a history of move success probabilities from past moves in order to weight moves better in the decision tree for MCTS. This program was run on multiple supercomputers that remarkably eclipse the computing power of typical everyday computers. In order to make such software trainable with limited resources, I would limit the recursive tree search to x turns. Instead of using a probabilistic approach to MCTS to decide moves because it would take an infinite number of turns to get a win or loss outcome, I would use a genetic algorithm to train a game state scoring function. The resulting scores of game states from these functions should backpropagate up the tree and will randomly mutated to improve the game scoring function. This combination of MCTS and genetic algorithms should work well with less computing power.
